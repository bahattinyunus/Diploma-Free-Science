# ğŸ•·ï¸ Proje: Data Harvesting Bot (Veri HasadÄ±)

**Zorluk**: ğŸŸ¡ Orta
**Alan**: Veri Bilimi / Python
**Tahmini SÃ¼re**: 1 Hafta

## ğŸ¯ AmaÃ§
Veri, yeni petroldÃ¼r. Ancak bu petrol kuyularÄ± (sosyal medya, haber siteleri) kilitlidir. Bu projede, kendi Yapay Zeka modelimizi eÄŸitmek iÃ§in web'den etik sÄ±nÄ±rlar iÃ§inde veri toplayan (scrape) bir bot yazacaÄŸÄ±z.

## ğŸ§° AraÃ§lar
1.  **Python**
2.  **BeautifulSoup4**: Statik HTML analizi iÃ§in.
3.  **Selenium / Playwright**: JavaScript Ã§alÄ±ÅŸtÄ±ran dinamik siteler iÃ§in.
4.  **SQLite**: Veriyi kaydetmek iÃ§in.

## ğŸ› ï¸ AdÄ±mlar

### 1. Hedef Belirleme
Hangi veriye ihtiyacÄ±nÄ±z var?
-   Haber manÅŸetleri? (Duygu analizi iÃ§in)
-   Ä°kinci el araba fiyatlarÄ±? (Piyasa tahmini iÃ§in)
-   Bilimsel makale Ã¶zetleri? (LLM eÄŸitimi iÃ§in)

### 2. Robot EtiÄŸi (robots.txt)
-   Hedef sitenin `domain.com/robots.txt` dosyasÄ±na bakÄ±n. "Disallow" (Ä°zin verilmez) denilen yerlere girmeyin.
-   Ä°stekler arasÄ±na 2-5 saniye bekleme sÃ¼resi koyun (`time.sleep()`). Sunucuyu Ã§Ã¶kertmeyin (DDoS yapmayÄ±n).

### 3. Kodlama (Basit Ã–rnek)
```python
import requests
from bs4 import BeautifulSoup

url = "https://news.ycombinator.com/"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

for item in soup.select('.titleline > a'):
    print(item.text)
```

### 4. Veri Temizleme & KayÄ±t
-   HTML etiketlerini temizleyin.
-   Veriyi temiz bir CSV veya JSON formatÄ±nda kaydedin.

## ğŸš€ Meydan Okuma
-   Botunuzu bir Raspberry Pi Ã¼zerinde 7/24 Ã§alÄ±ÅŸacak ÅŸekilde, verileri her gÃ¼n gÃ¼ncelleyip bir Dashboard'da gÃ¶sterecek hale getirin (Grafana veya Streamlit).
